{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Programming in Scala \n",
    "\n",
    "## Instructors: Viktor Kincak and Aleksander Prokopek\n",
    "\n",
    "> # Week 3: Data-Parallel Programming\n",
    "\n",
    "**Author:** [Ehsan M. Kermani](https://ca.linkedin.com/in/ehsanmkermani)\n",
    "\n",
    "Codes are available [here](https://github.com/axel22/parprog-snippets/tree/master/src/main/scala/lectures/dataparallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Parallelism vs. Data Parallelism:\n",
    "\n",
    "**Task parallel programming:** Form of parallelization that distributes *execution processes* across computing nodes \n",
    "\n",
    "* Previous lecture was about *task* and *parallel* constructs\n",
    "\n",
    "**Data parallel programming:** Form of parallelization that distributed *data* across computing nodes\n",
    "\n",
    "* Different data parallel programs have different workloads (workload is a function that maps each input element to the amount of work required to process it)\n",
    "\n",
    "* Goal of *data parallel scheduler* is to efficiently balance the workloads across processes without any knowledge of each individual workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala Data-Parallel Collections with `.par` method:\n",
    "* In Scala most collection operations can become data-parallel with `.par` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres0\u001b[0m: Int = \u001b[32m36\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// example: count the number of palindroms in parallel between 1 and 1000 (exclusive) divisible by 3\n",
    "(1 until 1000).par.filter(n => n % 3 == 0).count(n => n.toString == n.toString.reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* However, operations such as `foldLeft, foldRight, reduceLeft, reduceRight, scanLeft, scanRight` do not run in parallel even when invoked on parallel collections, due to their signatures being *dependent* and *waiting* for the previouly computed result(s). More precisly, the signature of foldLeft is as follows: `def foldLeft[B](zero: B)(f: (B, A) => B): B`, so the inner function $f: (B, A) => B$ causes the computation to run sequentially, as it waits for the previous computation to take place to use it as its first argument to do the next computation.\n",
    "\n",
    "\n",
    "* As seen in lecture 2, we can implement parallel `reduce` or in general `fold` (`\n",
    "def fold[A](zero: A)(f: (A, A) => A): A`) using three-like aggregation, with the condition that the structure the neutral element $zero$ and the binary operation $f$ form a [monoid](https://en.wikipedia.org/wiki/Monoid#Definition) i.e. the existent of associativity and identity. (Commutativity of $f$ is not a requirement)\n",
    "\n",
    "\n",
    "* It is possible to implement foldLeft-like operations (i.e. the operations where the resulting type can be *different* from the input type) in parallel. One such implementation is `aggregate` function containing a zero element `zero`, a sequential operation `seqOp` and parallel combine `combOp`:\n",
    "\n",
    "```scala\n",
    "def aggregate[B](zero: B)(seqOp: (B, A) => B, combOp: (B, B) => B): B\n",
    "```\n",
    "\n",
    "\n",
    "* Functions such as `sum, max, reduce, fold, count, aggregate`  etc. returning a single value on a parallel collection is called **accessors.** (In Apache Spark terminalogy, called *actions*).\n",
    "\n",
    "* Functions such as `map, flatMap, filter, groupBy` etc. returning a new collections as results are called **transformers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala Sequential and Parallel Collections Hierarchy:\n",
    "\n",
    "<img src=\"http://docs.scala-lang.org/resources/images/parallel-collections-hierarchy.png\",\n",
    "     height=1500, width=1000>\n",
    "     \n",
    "More details, [here](http://docs.scala-lang.org/overviews/collections/overview.html)\n",
    "\n",
    "* For codes that are agnostic about parallelism, there exists separate hierarchy of *generic* collection traits, like `GenIterable[T], GenSet[T]`, etc. (i.e. generic collection traits allow us to write code that is unaware of parallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-scala-api_2.10.5;0.2.0-SNAPSHOT from sonatype-snapshots, using Sun Oct 25 12:00:40 PDT 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-scala-api_2.10.5;0.2.0-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault#ammonite-api_2.10.5;0.3.1-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 02:44:30 PDT 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault#ammonite-api_2.10.5;0.3.1-SNAPSHOT\n",
      "\n",
      "\tUnable to reparse com.github.alexarchambault.jupyter#jupyter-api_2.10;0.2.0-SNAPSHOT from sonatype-snapshots, using Wed Oct 21 08:05:05 PDT 2015\n",
      "\n",
      "\tChoosing sonatype-snapshots for com.github.alexarchambault.jupyter#jupyter-api_2.10;0.2.0-SNAPSHOT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load.ivy(\"com.storm-enroute\" %% \"scalameter-core\" % \"0.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.scalameter._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mConversion\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Measure running times of changing two sequential collections \n",
    "// (List and (Immutable) Vector) into parallel ones. \n",
    "// See [[https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/lectures/dataparallelism/Conversion.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "import org.scalameter._\n",
    "\n",
    "object Conversion {\n",
    "  \n",
    "  val standardConfig = config(\n",
    "    Key.exec.minWarmupRuns -> 10,\n",
    "    Key.exec.maxWarmupRuns -> 20,\n",
    "    Key.exec.benchRuns -> 20,\n",
    "    Key.verbose -> true\n",
    "  ) withWarmer(new Warmer.Default)\n",
    "\n",
    "  val array = Array.fill(10000000)(\"\")\n",
    "  val list = array.toList\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    val listtime = standardConfig measure {\n",
    "      list.par\n",
    "    }\n",
    "    println(s\"list conversion time: $listtime ms\")\n",
    "\n",
    "    val arraytime = standardConfig measure {\n",
    "      array.par\n",
    "    }\n",
    "    println(s\"array conversion time: $arraytime ms\")\n",
    "    println(s\"difference: ${listtime / arraytime}\")\n",
    "  }\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting warmup.\n",
      "0. warmup run running time: 221.820565 (covNoGC: NaN, covGC: NaN)\n",
      "1. warmup run running time: 533.314673 (covNoGC: NaN, covGC: 0.5834)\n",
      "2. warmup run running time: 2197.968641 (covNoGC: NaN, covGC: 1.0794)\n",
      "3. warmup run running time: 234.193378 (covNoGC: 0.0384, covGC: 1.1861)\n",
      "4. warmup run running time: 252.429242 (covNoGC: 0.0384, covGC: 1.2413)\n",
      "5. warmup run running time: 236.479716 (covNoGC: 0.0342, covGC: 1.2824)\n",
      "6. warmup run running time: 276.521817 (covNoGC: 0.0342, covGC: 1.2900)\n",
      "7. warmup run running time: 240.561974 (covNoGC: 0.0346, covGC: 1.3051)\n",
      "8. warmup run running time: 255.199001 (covNoGC: 0.0346, covGC: 1.3072)\n",
      "9. warmup run running time: 235.397556 (covNoGC: 0.0302, covGC: 1.3123)\n",
      "10. warmup run running time: 238.179616 (covNoGC: 0.0280, covGC: 1.3062)\n",
      "11. warmup run running time: 266.96193 (covNoGC: 0.0280, covGC: 1.3908)\n",
      "12. warmup run running time: 236.163903 (covNoGC: 0.0257, covGC: 0.0605)\n",
      "Steady-state detected.\n",
      "Ending warmup.\n",
      "measurements: 234.793977, 241.443195, 251.178404, 229.758496, 229.644444, 248.078302, 229.473085, 229.760336, 229.447599, 248.003526, 229.705303, 238.98148, 250.860176, 231.769035, 230.658039, 239.396652, 230.276656, 231.394362, 230.031499, 289.135985\n",
      "list conversion time: 238.68952755 ms\n",
      "Starting warmup.\n",
      "0. warmup run running time: 10.038747 (covNoGC: NaN, covGC: NaN)\n",
      "1. warmup run running time: 4.807152 (covNoGC: 0.4984, covGC: 0.4984)\n",
      "2. warmup run running time: 5.76014 (covNoGC: 0.4057, covGC: 0.4057)\n",
      "3. warmup run running time: 9.650133 (covNoGC: 0.4057, covGC: 0.3525)\n",
      "4. warmup run running time: 6.462185 (covNoGC: 0.3375, covGC: 0.3215)\n",
      "5. warmup run running time: 4.522733 (covNoGC: 0.3511, covGC: 0.3500)\n",
      "6. warmup run running time: 4.662014 (covNoGC: 0.3469, covGC: 0.3583)\n",
      "7. warmup run running time: 6.52874 (covNoGC: 0.3145, covGC: 0.3319)\n",
      "8. warmup run running time: 5.246122 (covNoGC: 0.3008, covGC: 0.3247)\n",
      "9. warmup run running time: 5.063317 (covNoGC: 0.2912, covGC: 0.3200)\n",
      "10. warmup run running time: 7.048192 (covNoGC: 0.2760, covGC: 0.2605)\n",
      "11. warmup run running time: 6.996806 (covNoGC: 0.1716, covGC: 0.2467)\n",
      "12. warmup run running time: 8.176092 (covNoGC: 0.1716, covGC: 0.2546)\n",
      "13. warmup run running time: 4.420977 (covNoGC: 0.1809, covGC: 0.2195)\n",
      "14. warmup run running time: 4.651073 (covNoGC: 0.1932, covGC: 0.2335)\n",
      "15. warmup run running time: 5.533551 (covNoGC: 0.1878, covGC: 0.2183)\n",
      "16. warmup run running time: 5.942363 (covNoGC: 0.1744, covGC: 0.2022)\n",
      "17. warmup run running time: 5.153205 (covNoGC: 0.1656, covGC: 0.2081)\n",
      "18. warmup run running time: 6.55106 (covNoGC: 0.1659, covGC: 0.2037)\n",
      "19. warmup run running time: 6.942626 (covNoGC: 0.1727, covGC: 0.1962)\n",
      "Steady-state not detected.\n",
      "measurements: 7.676298, 4.394889, 4.391965, 4.446678, 4.518431, 4.40099, 4.389856, 4.491218, 4.516116, 6.542636, 4.426475, 5.717215, 6.96212, 7.32568, 4.805791, 5.143272, 5.106757, 4.468038, 10.135121, 6.137834\n",
      "array conversion time: 5.4998689999999995 ms\n",
      "difference: 43.39912960654154\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Conversion.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizable Collections:\n",
    "\n",
    "* Examples: the followings all have sequential counterpart, `ParArray[A], RapRange[A], ParVector[A], immutable.ParHashSet[T], immutable.ParHashMap[K, V], mutable.ParHashSet[T], mutable.ParHashMap[K, V]`\n",
    "\n",
    "\n",
    "* `ParTrieMap[K, V]`: *thread-safe* parallel map with *atomic snapshots* counter part of `TrieMap[K, V]`\n",
    "\n",
    "\n",
    "* Other collections, `.par` creates the closes parallel collection, e.g. `List` to `ParVector` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules Working with Parallel Collections:\n",
    "\n",
    "### Rule 1: Avoid mutations to the same memory locations without proper synchronization\n",
    "\n",
    "**Example: Side-effect operations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.scalameter._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mIntersectionWrong\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// See [[https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/lectures/dataparallelism/IntersectionWrong.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "import org.scalameter._\n",
    "\n",
    "object IntersectionWrong {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    def intersection(a: GenSet[Int], b: GenSet[Int]): Set[Int] = {\n",
    "      val result = mutable.Set[Int]() // mutable culprite!\n",
    "      for (x <- a) if (b contains x) result += x\n",
    "      result\n",
    "    }\n",
    "    val seqres = intersection((0 until 1000).toSet, (0 until 1000 by 4).toSet)\n",
    "    val parres = intersection((0 until 1000).par.toSet, (0 until 1000 by 4).par.toSet)\n",
    "    log(s\"Sequential result - ${seqres.size}\")\n",
    "    log(s\"Parallel result   - ${parres.size}\")\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential result - 250\n",
      "Parallel result   - 249\n",
      "Sequential result - 250\n",
      "Parallel result   - 251\n",
      "Sequential result - 250\n",
      "Parallel result   - 250\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// see the disparity between sequential result and parallel\n",
    "IntersectionWrong.main(Array(\"start\"))\n",
    "IntersectionWrong.main(Array(\"start\"))\n",
    "IntersectionWrong.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mscala.collection.convert.wrapAsScala._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.util.concurrent._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.scalameter._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mIntersectionSynchronized\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// See [[https://raw.githubusercontent.com/axel22/parprog-snippets/master/src/main/scala/lectures/dataparallelism/IntersectionSynchronized.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "import scala.collection.convert.wrapAsScala._\n",
    "import java.util.concurrent._\n",
    "import org.scalameter._\n",
    "\n",
    "object IntersectionSynchronized {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    def intersection(a: GenSet[Int], b: GenSet[Int]) = {\n",
    "      val result = new ConcurrentSkipListSet[Int]()\n",
    "      for (x <- a) if (b contains x) result += x\n",
    "      result\n",
    "    }\n",
    "    val seqres = intersection((0 until 1000).toSet, (0 until 1000 by 4).toSet)\n",
    "    val parres = intersection((0 until 1000).par.toSet, (0 until 1000 by 4).par.toSet)\n",
    "    log(s\"Sequential result - ${seqres.size}\")\n",
    "    log(s\"Parallel result   - ${parres.size}\")\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential result - 250\n",
      "Parallel result   - 250\n",
      "Sequential result - 250\n",
      "Parallel result   - 250\n",
      "Sequential result - 250\n",
      "Parallel result   - 250\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// correct\n",
    "IntersectionSynchronized.main(Array(\"start\"))\n",
    "IntersectionSynchronized.main(Array(\"start\"))\n",
    "IntersectionSynchronized.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: Avoiding side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.scalameter._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mIntersectionCorrect\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// See [[https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/lectures/dataparallelism/IntersectionCorrect.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "import org.scalameter._\n",
    "\n",
    "object IntersectionCorrect {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    def intersection(a: GenSet[Int], b: GenSet[Int]): GenSet[Int] = {\n",
    "      if (a.size < b.size) a.filter(b(_))\n",
    "      else b.filter(a(_))\n",
    "    }\n",
    "    val seqres = intersection((0 until 1000).toSet, (0 until 1000 by 4).toSet)\n",
    "    val parres = intersection((0 until 1000).par.toSet, (0 until 1000 by 4).par.toSet)\n",
    "    log(s\"Sequential result - ${seqres.size}\")\n",
    "    log(s\"Parallel result   - ${parres.size}\")\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential result - 250\n",
      "Parallel result   - 250\n",
      "Sequential result - 250\n",
      "Parallel result   - 250\n",
      "Sequential result - 250\n",
      "Parallel result   - 250\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IntersectionCorrect.main(Array(\"start\"))\n",
    "IntersectionCorrect.main(Array(\"start\"))\n",
    "IntersectionCorrect.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule 2: Never modify a parallel collection on which a data-parallel operation is in progress\n",
    "\n",
    "* Never write to a collection that is concurrently traversed\n",
    "\n",
    "* Never read from a collection that is concurrently modified\n",
    "\n",
    "* In either case, the result can be *non-deterministic*\n",
    "\n",
    "**Example: Concurrent modifications during traversals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mParallelGraphContraction\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// See [[https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/lectures/dataparallelism/ParallelGraphContraction.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "\n",
    "object ParallelGraphContraction {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    val graph = mutable.Map[Int, Int]() ++= (0 until 100000).map(i => (i, i + 1))\n",
    "    graph(graph.size - 1) = 0\n",
    "    for ((k, v) <- graph.par) graph(k) = graph(v)\n",
    "    val violation = graph.find({ case (i, v) => v != (i + 2) % graph.size })\n",
    "    println(s\"violation: $violation\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: Some((41623,41627))\n",
      "violation: Some((41623,41626))\n",
      "violation: Some((41623,41626))\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// violations exit!\n",
    "ParallelGraphContraction.main(Array(\"start\"))\n",
    "ParallelGraphContraction.main(Array(\"start\"))\n",
    "ParallelGraphContraction.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrieMap Collection is an *exception* to above rules because of the snapshot method used to correctly grab the current state\n",
    "\n",
    "* snapshot is of $O(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.collection._\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mParallelTrieMapGraphContraction\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// See [[https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/lectures/dataparallelism/ParallelTrieMapGraphContraction.scala]]\n",
    "\n",
    "import scala.collection._\n",
    "\n",
    "object ParallelTrieMapGraphContraction {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    val graph = concurrent.TrieMap[Int, Int]() ++= (0 until 100000).map(i => (i, i + 1))\n",
    "    graph(graph.size - 1) = 0\n",
    "    val previous = graph.snapshot()\n",
    "    for ((k, v) <- graph.par) graph(k) = previous(v)\n",
    "    val violation = graph.find({ case (i, v) => v != (i + 2) % graph.size })\n",
    "    println(s\"violation: $violation\")\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: None\n",
      "violation: None\n",
      "violation: None\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ParallelTrieMapGraphContraction.main(Array(\"start\"))\n",
    "ParallelTrieMapGraphContraction.main(Array(\"start\"))\n",
    "ParallelTrieMapGraphContraction.main(Array(\"start\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Parallel Abstractions:\n",
    "\n",
    "* Iterators\n",
    "* Splitters\n",
    "* Builders\n",
    "* Combiners\n",
    "\n",
    "Follow abstraction are simplified:\n",
    "\n",
    "### Iterator:\n",
    "\n",
    "```scala\n",
    "trait Iterator[A] {\n",
    "    def next: A\n",
    "    def hasNext: Boolean\n",
    "}\n",
    "\n",
    "def iterator: Iterator[A] // must be implemented on every collection\n",
    "```\n",
    "\n",
    "* `next` can be called only if `hasNext` return `true`\n",
    "* after `hasNext` returns `false`, it will always return `false`\n",
    "\n",
    "### Splitter:\n",
    "\n",
    "```scala\n",
    "trait Splitter[A] extends Iterator[A] {\n",
    "    def split: Seq[Splitter[A]]\n",
    "    def remaining: Int\n",
    "}\n",
    "\n",
    "def splitter: Splitter[A] // must be implemented on every *parallel* collection\n",
    "```\n",
    "\n",
    "* after calling `split`, the original splitter is left in an undefined state\n",
    "* the resulting splitters travere disjoint subsets of the original splitter\n",
    "* `remaining` is an estimate on the number of remaining elements\n",
    "* `split` is an efficient method $O(\\log n)$ or better\n",
    "\n",
    "### Builder:\n",
    "\n",
    "```scala\n",
    "trait Builder[A, Repr] { // Repr denotes the type of collection that Builder creates\n",
    "    def +=(elem: A): Builder[A, Repr]\n",
    "    def result: Repr\n",
    "}\n",
    "def newBuilder: Builder[A, Repr] // must be defined on every collection\n",
    "\n",
    "```\n",
    "* calling `result` returns a collection of type `Repr`, containing the elements tha were previously added with `+=`\n",
    "* calling `result` leaves the `Builder` in an undefined state\n",
    "\n",
    "### Combiner:\n",
    "\n",
    "```scala\n",
    "trait Combiner[A, Repr] extends Builder[A, Repr] {\n",
    "    def combine(that: Combiner[A, Repr]): Combiner[A, Repr] \n",
    "}\n",
    "\n",
    "def newCombiner: Combiner[T, Repr] // must be implemented on every *parallel* collection\n",
    "\n",
    "```\n",
    "\n",
    "* calling `combine` returns a new `Combiner` that contains elements of input combiners\n",
    "* calling `combine` leaves both original `Combiner`s in an undefined state\n",
    "* `combine` is an efficient method $O(\\log n)$ or better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala210",
   "name": "scala210"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala210",
   "pygments_lexer": "scala",
   "version": "2.10.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
